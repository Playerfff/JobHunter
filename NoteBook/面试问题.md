## 自我介绍

面试官，您好。

我是王逸飞，来自吉林大学软件工程专业,目前大四就读。我对软件开发充满热情，并在C/C++、QT和分布式方向上积累了丰富的技术经验。

在我的学习过程中，我致力于不断提升自己的技能，并在各种项目中将所学知识转化为实际成果。我对于挑战和解决问题的热情使我能够在团队中发挥积极作用，我喜欢与他人合作，分享知识，共同实现项目目标。

我相信我的技术背景和团队合作精神使我成为这个职位的合适候选人，并且我迫不及待地期待着能够为贵公司贡献自己的力量。

我的自我介绍到此结束.

## 介绍自己性能优化的一些经验

1. 首先使用`perf`工具去查询一下整个程序在运行时候的调用堆栈, 得到**火焰图**;
2. 分析火焰图, 找出制约代码运行效率的**短板**(木桶效应), 针对性的优化。
3. 充分利用多核处理器的优势， 使用`线程`或`异步编程`可以使程序相应更加迅速；
4. `内存管理`, 可以使用tcmalloc之类的分配器去减少动态内存分配的次数, 尽量使用栈上分配内存;
5. `编译器的优化`, 编译器的优化参数很大程度上影响release版本的性能。
6. 算法和数据结构的优化；
7. 多线程中锁策略的优化；
8. `关键代码汇编级优化`, `提高缓存击中`。

### 工具角度

1. 首先得熟悉一些相关性能优化的工具，利用perf对函数级别去了解各个函数的开销
2. 利用on cpu火焰图去了解 CPU 执行的代码路径，off cpu火焰图去解决在等待外部资源时的性能问题
3. 在调优完毕后，`差分火焰图`可以帮助我们快速的进行回归验证，比较两个火焰图的变化。
4. 使用tracing工具在进程中打一些点，了解不同操作的延迟，针对延迟较高的地方进行优化

### 架构角度(common 思想)

1. 针对磁盘访问较重的地方，尽量增加一些缓存
2. 减少同步逻辑，变为异步逻辑
3. 基于不同的负载划分不同大小的线程池

## 介绍内存问题调查一些经验

### 内存泄漏

1. 表现: 内存有缓慢上涨
2. 对策: valgrind / asan / 使用tcmalloc替换malloc

## final
final声明的类不可被继承

## const
修饰对象使其仅可读  
1. top-level const: 指针自身不可变
> const int* p
2. low-level const: 指针所指不可变
> int* const p
3. 修饰类的成员函数, 标明此函数不可修改非`mutable`对象

## mutex
1. 互斥量, 用于多线程顺序访问共享变量, 得锁者可访问变量
2. shared_mutex: 共享锁

    使用shared_mutex实现读写锁: `可多读, 仅一写`
```c++
#include <iostream>
#include <shared_mutex>
#include <thread>

class ReadWriteLock {
public:
    void readOperation(int threadId) {
        std::shared_lock<std::shared_mutex> lock(mutex_);
        std::cout << "Thread " << threadId << " is reading." << std::endl;
        // 执行读操作
    }

    void writeOperation(int threadId) {
        std::unique_lock<std::shared_mutex> lock(mutex_);
        std::cout << "Thread " << threadId << " is writing." << std::endl;
        // 执行写操作
    }

private:
    std::shared_mutex mutex_;
};
```

3. 悲观锁和乐观锁
    1. 悲观锁（Pessimistic Locking）：

        1. 特点： 假设在并发环境下，会有冲突的情况，因此在整个操作过程中假设最坏的情况，认为随时可能会有其他线程干扰，因此采用悲观的态度。在执行操作之前，悲观锁会先对共享资源进行加锁，确保在整个操作期间资源不会被其他线程访问。
        2. 实现方式： 使用互斥锁（mutex）等同步机制来保护共享资源，阻止其他线程同时访问。
    2. 乐观锁（Optimistic Locking）：

        1. 特点： 假设在并发环境下，冲突的情况较少，因此在整个操作过程中采用乐观的态度。在执行操作之前，并不直接对共享资源进行加锁，而是在操作完成之前检查是否有其他线程对资源进行了修改。如果没有发现冲突，操作继续执行，否则，可能进行回滚、重试等处理。
        2. 实现方式： 通常使用版本号、时间戳等机制来检测共享资源的变化，而不是直接加锁。
    3. 区别总结：

        1. 悲观锁：

        > 假设会有冲突，因此在整个操作期间加锁。
        适用于写操作较频繁的场景，适合于保持较长时间的锁。
        常见的实现方式包括互斥锁、读写锁等。
        2. 乐观锁：

        > 假设冲突较少，因此在整个操作期间不加锁，而是在操作完成前检查是否有冲突。适用于读操作较频繁的场景，适合于保持较短时间的锁。
        常见的实现方式包括版本号控制、时间戳等。

4. spinlock & non-spinlock
    1. spinlock: busy-wait;
    2. non-spinlock: lock不了就睡眠.

## dynamic_cast
1. 消耗运行期时间, 会从父类遍历整个对象树, 直到找到符合预期或遍历完对象树为止。
2. 避免写出如下代码：
![Alt text](./image/image-6.png)

## virtual dtor
1. 必须设置虚拟析构, 否则使用父类指针存储子类对象, 析构时只能调用父类析构函数, 从而资源泄露;
2. 即使没有设置虚拟析构, 编译器也发现不了;

## 智能指针
1. unique_ptr: 独享资源, 不可复制, 只可转移;
2. shared_ptr: 引用计数, 可复制;
3. weak_ptr: 解决循环引用导致的无法析构的问题; for example:
```c++
#include <iostream>
#include <memory>

class B;

class A
{
    public:
    std::shared_ptr<B> _ptr;

    public:
    A()
    {
        std::cout << "A ctor." << std::endl;
    }
    ~A()
    {
        std::cout << "A dtor." << std::endl;
    }
}

class B
{
    public:
    std::shared_ptr<B> _ptr;

    public:
    B()
    {
        std::cout << "B ctor." << std::endl;
    }
    ~B()
    {
        std::cout << "B dtor." << std::endl;
    }
}

int main()
{
    {
        A a();
        B b();
        a._ptr = b;
        b._ptr = a;
    }
    std::cout << "cannot be destrcted." << std::endl;
}
```

4. 什么时候只能使用裸指针:
    1. qt ui*;
    2. shared_ptr在函数间传递导致生命周期不明确时, 就可手动接管.

# 线程池

```c++
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <functional>
#include <queue>

class ThreadPool {
public:
    ThreadPool(int numThreads) : stop(false) {
        for (int i = 0; i < numThreads; ++i) {
            threads.emplace_back([this] {
                while (true) {
                    std::unique_lock<std::mutex> lock(mutex);
                    condition.wait(lock, [this] { return stop || !tasks.empty(); });
                    if (stop && tasks.empty()) {
                        return;
                    }
                    std::function<void()> task(std::move(tasks.front()));
                    tasks.pop();
                    lock.unlock();
                    task();
                }
            });
        }
    }

    ~ThreadPool() {
        {
            std::unique_lock<std::mutex> lock(mutex);
            stop = true;
        }
        condition.notify_all();
        for (std::thread& thread : threads) {
            thread.join();
        }
    }

    template<typename F, typename... Args>
    void enqueue(F&& f, Args&&... args) {
        std::function<void()> task(std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        {
            std::unique_lock<std::mutex> lock(mutex);
            tasks.emplace(std::move(task));
        }
        condition.notify_one();
    }

private:
    std::vector<std::thread> threads;
    std::queue<std::function<void()>> tasks;
    std::mutex mutex;
    std::condition_variable condition;
    bool stop;
};

int main() {
    ThreadPool pool(4);
    for (int i = 0; i < 8; ++i) {
        pool.enqueue([i] {
            std::cout << "Task " << i << " is running in thread " << std::this_thread::get_id() << std::endl;
            std::this_thread::sleep_for(std::chrono::seconds(1));
            std::cout << "Task " << i << " is done" << std::endl;
        });
    }
    return 0;
}
```

# 五种IO模型和epoll详解

