## OSI计算机七层架构

1. 应用层
    1. 各种应用软件
2. 表示层
    1. 数据格式标识，基本压缩加密功能。
3. 会话层
    1. 控制应用程序之间会话能力；如不同软件数据分发给不同软件。
4. 传输层
    1. 数据被称为tcp报文或者udp数据报
    2. 端到端传输数据的基本功能；如 TCP、UDP。
5. 网络层
    1. 数据被称为包(packages)
    2. 定义IP编址，定义路由功能；如不同设备的数据转发。
6. 数据链路层
    1. 数据被称为frames(帧)
    2. 定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。
7. 物理层
    1. 数据被称为bits(比特流)
    2. 底层数据传输，如网线；网卡标准。

计算机网络被分为多个层次，通常使用OSI（开放系统互连）模型或TCP/IP协议套件模型，这些模型将网络功能分解成不同的层次或层次组件。这种分层的方法有以下几个主要原因：

**为什么计算机网络要分层？**
1. **模块化和分工明确**：

- 分层允许将网络功能划分为独立的模块或层次，每个层次负责特定的任务和功能。这使得网络设计、开发和维护更加可管理，因为每个层次可以独立开发和维护。

2. **互操作性**：

- 不同供应商和组织可以根据相同的协议规范实现网络层次中的特定层次，而不必关心其他层次的具体实现。这提高了不同设备和系统之间的互操作性，使它们能够有效地协同工作。

3. **易于维护和升级**：

- 分层架构允许在不影响整个网络的情况下进行单个层次的更改、升级或替换。这有助于网络的可维护性，因为不必重构整个网络来引入变化。

4. **简化复杂性**：

- 将网络功能分解成小块层次可以降低整体网络的复杂性。每个层次只需关注自己的任务，而不必处理与其他层次相关的所有细节。

5. **跨平台和跨技术**：

- 分层方法有助于实现跨不同平台、技术和物理媒体的网络通信。不同层次的标准化使得可以在不同环境中使用相同的协议来构建网络。

6. **教学和理解**：

- 分层模型对于教学和理解网络概念非常有帮助，因为它允许学生和专业人员逐层深入了解网络运行和交互的方式。

总之，分层的计算机网络模型提供了一种组织网络功能和通信的有效方法，使网络更加可管理、可维护、互操作，并且有助于降低复杂性，促进网络的发展和创新。它是构建现代计算机网络的关键设计原则之一。




## 概述

1. P2P和CS网络有什么区别?
    1. **数据分发方式**:
   - *P2P网络*：在P2P网络中，所有参与者（通常称为节点）都可以充当客户端和服务器，它们可以相互通信和分享资源。没有中央服务器，所有节点在平等地共享数据和资源。
   - *CS网络*：在CS网络中，有一个或多个中央服务器，这些服务器负责存储和管理数据，而客户端设备从服务器请求数据。客户端设备通常只具有有限的功能，如浏览网页或下载文件。

    2. **中心化与分散化**:
   - *P2P网络*：P2P网络通常是分散的，没有单一的中央实体控制网络的运作。每个节点在网络中都是平等的，它们彼此协作来共享数据和资源。
   - *CS网络*：CS网络是中心化的，由一个或多个中央服务器控制和管理。客户端设备依赖于服务器来提供数据和服务。

    3. **可伸缩性**:
   - *P2P网络*：P2P网络通常更具可伸缩性，因为每个新节点的加入会增加资源和带宽的可用性。网络的性能不会因节点数量的增加而降低。
   - *CS网络*：CS网络的性能受到服务器的限制，如果客户端数量增加，服务器可能需要更多的处理能力和带宽来满足需求。

    4. **冗余和稳定性**:
   - *P2P网络*：P2P网络通常具有较高的冗余性，因为数据通常存在于多个节点上，如果一个节点出现故障，其他节点仍然可以提供数据。
   - *CS网络*：CS网络的稳定性通常依赖于服务器的稳定性，如果服务器出现故障，可能会导致整个网络不可用。

    5. **安全性**:
   - *P2P网络*：P2P网络的安全性较低，因为数据和资源可以在多个节点之间共享，难以控制和保护敏感信息。
   - *CS网络*：CS网络可以实施更强大的安全措施，因为数据存储在服务器上，可以更容易地进行管理和保护。

    总的来说，P2P和CS网络各有优点和缺点，适用于不同的用例和需求。P2P网络通常更适合分散化的数据共享和资源共享，而CS网络更适合中央控制和数据管理的应用。

2. 什么是速率、带宽、延迟?
    1. **速率（Data Rate）**：
    - 速率是指单位时间内传输的数据量，通常以比特每秒（bps）为单位表示。速率可以描述数据传输的**快慢**，较高的速率表示更多数据在单位时间内传输，而较低的速率表示传输速度较慢。
    - 速率通常用来衡量网络连接或通信通道的性能，例如，网络连接的速率可以是1 Gbps（千兆比特每秒）或10 Mbps（百万比特每秒）。

    2. **带宽（Bandwidth）**：
    - 带宽是指通信通道的能力，即它可以传输的最大数据量。带宽通常以比特每秒（bps）为单位表示，类似于速率。
    - 带宽描述了通信通道的容量，而速率描述了实际数据传输的速度。带宽可以看作是通信通道的最大速率，但实际速率可能低于带宽，受到网络流量和其他因素的影响。

    3. **延迟（Latency）**：
    - 延迟是指从数据发送到数据到达目的地所需的**时间**。延迟可以分为多个不同的部分，包括传播延迟、传输延迟、排队延迟和处理延迟。
    - 传播延迟是信号在传输媒介中传播所需的时间，而传输延迟是数据从发送端到接收端所需的时间，排队延迟是数据在网络设备中排队等待处理的时间，处理延迟是数据在设备中进行处理的时间。
    - 总延迟是这些不同延迟的总和，它影响了通信的响应时间。较低的延迟通常表示更快的通信。

3. 什么是丢包率、吞吐量
    1. 丢包率是指在数据传输过程中丢失的数据包的比率。
    2. 吞吐量是指在单位时间内通过网络或通信通道传输的实际数据量。它表示网络的数据传输能力，通常以比特每秒（bps）或字节每秒（Bps）为单位表示。


## 应用层

1. 应用层有哪些协议?
- HTTP
- FTP
- DNS
- SMTP / POP3

2. DNS是什么？它的作用是什么？DNS解析过程是怎样的？
    1. DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。

        通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。
    2. 过程：浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存。 一、主机向本地域名服务器的查询一般都是采用递归查询。 二、本地域名服务器向根域名服务器的查询的迭代查询。

        当用户输入域名时，浏览器先检查自己的缓存中是否包含这个域名映射的ip地址，有解析结束。 2）若没命中，则检查操作系统缓存（如Windows的hosts）中有没有解析过的结果，有解析结束。 3）若无命中，则请求本地域名服务器解析（LDNS）。 4）若LDNS没有命中就直接跳到根域名服务器请求解析。根域名服务器返回给LDNS一个 主域名服务器地址。 5）此时LDNS再发送请求给上一步返回的gTLD（ 通用顶级域）， 接受请求的gTLD查找并返回这个域名对应的Name Server的地址 6）Name Server根据映射关系表找到目标ip，返回给LDNS
    LDNS缓存这个域名和对应的ip， 把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束.
    3. DNS使用UDP协议,因为快,而且传输数据量也不是很大,一个报文就足够.

3. 网络中如何寻址进程？
    1. IP地址和端口号;
    2. 域名和主机名(DNS);

### HTTP
1. HTTP协议是什么？它的工作原理是什么？常见的HTTP请求方法有哪些？
    1. 什么是HTTP协议？

        HTTP（Hypertext Transfer Protocol）是一种应用层协议，用于在计算机之间传输超文本数据，如文本、图像、音频和视频等。HTTP协议是Web的基础，它在Web浏览器和Web服务器之间进行数据传输。

    2. HTTP的工作原理

        HTTP的工作原理如下：

        1. **客户端发出请求**：通常由Web浏览器（例如Chrome、Firefox）作为客户端，用户在浏览器中输入URL或点击链接，触发HTTP请求。

        2. **DNS解析**：如果用户输入了URL，浏览器首先执行DNS解析，将域名解析为IP地址，以确定要连接的服务器位置。

        3. **建立TCP连接**：浏览器使用计算机的操作系统内核中的TCP/IP协议栈来建立到Web服务器的TCP连接，通常在端口80上。

        4. **发出HTTP请求**：一旦建立连接，浏览器向服务器发送HTTP请求，包括请求方法（如GET、POST）、URL、HTTP版本、请求头和请求正文（对于POST请求）等。

        5. **服务器处理请求**：Web服务器接收HTTP请求后，根据请求中的信息来处理请求，可能涉及读取文件、数据库查询、生成动态内容等。

        6. **服务器返回HTTP响应**：服务器生成HTTP响应，包括响应状态码、响应头和响应正文。响应状态码指示请求是否成功（例如，200表示成功，404表示未找到，500表示服务器内部错误）。

        7. **数据传输**：服务器通过TCP连接将HTTP响应传输到客户端。

        8. **客户端渲染和呈现**：一旦浏览器接收到HTTP响应，它解析响应，加载资源（例如HTML、CSS、JavaScript、图像等）并将页面呈现给用户。

        9. **关闭连接**：当响应传输完成后，TCP连接可以关闭或保持活动以供后续请求重用。

    3. 常见的HTTP请求方法

        HTTP定义了多种请求方法，常见的包括：

        1. **GET**：用于从服务器获取数据，通常用于请求网页和资源。它是幂等的，不应该对服务器状态产生影响。

        2. **POST**：用于将数据发送到服务器，通常用于提交表单数据、上传文件等。它不是幂等的，可能对服务器状态产生影响。

        3. **PUT**：用于将数据放到指定的URL下，通常用于更新资源。

        4. **DELETE**：用于从服务器删除指定资源。

        5. **HEAD**：类似于GET，但只返回响应头，不包括响应正文。通常用于检查资源是否存在或获取资源的元数据。

        6. **OPTIONS**：用于获取有关服务器支持的请求方法和其他信息。

        7. **PATCH**：用于部分更新资源，通常包括只更新资源的一部分数据。
    
    4. get和post的区别?
        1. get获取数据, post提交数据;
        2. get把请求的数据放在url上， 以?分割URL和传输数据，参数之间以&相连，所以get不太安全。而post把数据放在HTTP的包体内（request body 相对安全）
        3. get提交的数据最大是2k（ 限制实际上取决于浏览器）， post理论上没有限制;
        4. **GET是幂等的，而POST不是幂等的**;
        5. 正因为它们有这样的区别，所以不应该且不能用get请求做数据的增删改这些有副作用的操作。因为get请求是幂等的，在网络不好的隧道中会尝试重试。如果用get请求增数据，会有重复操作的风险，而这种重复操作可能会导致副作用（浏览器和操作系统并不知道你会用get请求去做增操作）。

    5. HTTP请求和响应的结构是怎样的？
    ```http
        GET /index.html HTTP/1.1
        Host: www.example.com
        User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.182 Safari/537.36
        Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
    ```

    6. HTTP cookie:

    HTTP cookie（HTTP Cookie）是一种用于在Web浏览器和Web服务器之间跟踪用户状态和存储信息的小型文本文件。它是一种在客户端（通常是Web浏览器）和服务器之间进行数据交换的机制，用于在不同的HTTP请求之间保持用户的状态信息。

    7. HTTP缓存的作用是什么？
    
    HTTP缓存的作用是提高Web应用程序的性能、降低服务器负载，以及减少页面加载时间。通过在客户端和服务器之间缓存资源（如网页、图像、样式表和脚本），HTTP缓存允许浏览器在后续请求相同资源时不必重新从服务器获取资源，而是可以直接从本地缓存中获取。

### socket编程

1. 如何创建一个socket连接？如何在服务器和客户端之间建立通信？
    - 服务器端
    1. 创建socket对象
    2. bind socket到指定ip和端口号, 这将告诉操作系统将传入的连接请求路由到该Socket。
    3. listen连接请求;
    4. accept连接;
    5. 与client通信;

    - 客户端
    1. 创建一个socket对象
    2. connect建立连接到server;
    3. 与server通信.

2. socket编程中如何进行负载均衡和故障转移？

    在Socket编程中，实现负载均衡和故障转移通常需要使用一些高级的技术和策略。以下是一些方法和工具，可以帮助你实现负载均衡和故障转移：

    **1. 负载均衡：**

    负载均衡是将请求分发到多个服务器以平衡负载，以确保每个服务器都能够有效地处理请求。以下是一些实现负载均衡的方法：

    - **硬件负载均衡器**：使用专门的硬件设备，如负载均衡器，它可以在多个服务器之间分发流量。
    - **软件负载均衡器**：使用软件负载均衡器，如Nginx、HAProxy等，它们可以在应用层或传输层进行负载均衡。
    - **DNS负载均衡**：使用DNS服务器配置多个IP地址，每个IP地址映射到不同的服务器。DNS服务器可以将请求分发到这些IP地址，实现负载均衡。

    **2. 故障转移：**

    故障转移是在服务器发生故障时将流量转移到其他服务器，以确保服务的可用性。以下是一些实现故障转移的方法：

    - **健康检查**：定期检查服务器的健康状态，如果服务器出现故障，将其从负载均衡池中移除。
    - **热备份**：配置热备份服务器，当主服务器发生故障时，自动切换到备份服务器。
    - **共享存储**：使用共享存储来存储数据，多个服务器可以访问相同的数据。当一个服务器出现故障时，另一个服务器可以接管服务。

    **3. 自动化和监控：**

    使用自动化工具和监控系统来检测故障并执行自动故障转移操作。例如，使用工具如Kubernetes、Docker Swarm等来管理容器化应用程序，它们具有自动负载均衡和故障转移功能。

    **4. 心跳检测和健康检查：**

    实现心跳检测以监控服务器的活动状态。如果服务器长时间没有响应心跳检测，可以将其标记为故障服务器，并将流量转移到其他服务器。

    在Socket编程中，实现心跳检测和超时处理是确保连接的稳定性和可靠性的关键部分。心跳检测是一种机制，允许一方定期向另一方发送消息以确认连接的存活性。如果长时间没有收到心跳消息，可以触发超时处理来断开连接或采取其他必要的操作。以下是实现心跳检测和超时处理的一般步骤：

    **心跳检测**：

    - 协商心跳间隔：在连接建立时，服务器和客户端之间应协商心跳消息的发送间隔。通常，心跳间隔是一种可配置的参数，取决于应用的需求。

    - 定时发送心跳消息：服务器和客户端分别定时发送心跳消息，以确认对方的存活性。心跳消息可以是一个特定的协议消息，例如PING或PONG。

    - 接收心跳消息：在接收到对方的心跳消息时，应该确认消息的到达并重置计时器。这表明对方仍然活着。

    **超时处理**：

    - 设置超时计时器：为每个连接设置一个超时计时器，计时器的值应该稍长于心跳间隔，以容忍一定的网络延迟。

    - 监视超时：定期检查超时计时器是否超时。如果计时器超时，表示已经长时间没有收到心跳消息，说明对方可能已经断开连接或遇到问题。

    - 超时处理操作：一旦发生超时，可以采取以下操作之一：

            断开连接：关闭连接，释放资源。

            重新连接：尝试重新建立连接，以恢复通信。

            报告错误：通知应用程序连接已经超时，应用程序可以根据需要进行处理。
            
            采取其他操作：根据应用程序的需求，执行其他适当的操作。

    **5. 数据复制和冗余：**

    使用数据复制和冗余技术来确保数据的可用性。如果一个服务器发生故障，备份服务器可以接管并提供服务。

    需要注意的是，实现负载均衡和故障转移通常取决于你的应用程序和基础架构的需求。不同的场景可能需要不同的策略和工具。因此，在设计和实施负载均衡和故障转移时，需要仔细考虑应用程序的特性和可用的资源。
